{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wjVEJ3-AEfyo"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_words.pkl', 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "with open('train_tags.pkl', 'rb') as f:\n",
    "    tags = pickle.load(f)\n",
    "\n",
    "# sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GY6471wcMxfe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, valid_sentences, train_taggings, valid_taggings = train_test_split(sentences, tags, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rFnH4W66P_L",
    "outputId": "39abbd4e-a700-4e54-faf7-bbb28143a754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Até', 'ADP'), ('hoje', 'ADV'), ('sou', 'VERB'), ('cineasta', 'NOUN'), (',', 'UNK'), ('estou', 'UNK'), ('trabalhando', 'VERB'), ('em', 'UNK'), ('um', 'DET'), ('filme', 'NOUN'), ('sobre', 'ADP'), ('a', 'DET'), ('esquerda', 'NOUN'), ('americana', 'ADJ'), ('para', 'ADP'), ('a', 'DET'), ('televisão', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(train_sentences[30], train_taggings[30])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCw5BN2t6SDA",
    "outputId": "689784d6-903b-4cf1-dad7-222ce843f8b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different tags: 14\n",
      "475370 UNK\n",
      "358565 NOUN\n",
      "174499 DET\n",
      "169939 ADP\n",
      "142766 VERB\n",
      "94035 .\n",
      "84736 ADJ\n",
      "46317 ADV\n",
      "31477 CONJ\n",
      "30806 PRON\n",
      "30007 NUM\n",
      "8865 PRT\n",
      "7807 X\n",
      "9 INTJ\n"
     ]
    }
   ],
   "source": [
    "# use a defaultdict to count the number of occurrences of each tag\n",
    "import collections\n",
    "tagset = collections.defaultdict(int)\n",
    "\n",
    "for tagging in train_taggings:\n",
    "  for tag in tagging:\n",
    "    tagset[tag] += 1\n",
    "\n",
    "print('number of different tags:', len(tagset))\n",
    "\n",
    "# print count and tag sorted by decreasing count\n",
    "for tag, count in sorted(tagset.items(), reverse=True, key=lambda x: x[1]):\n",
    "  print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "JnJmPY8J6UoU",
    "outputId": "c316600a-7edc-435c-e868-a96c1f178b97"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVdklEQVR4nO3db6ye9X3f8fendkJJWv7GIGajmQgrm0EKCRZzlqnq4q44TRTzAKQTLcPbPHlCbEq2SZ1ZHkx9YAm2qXRogwmFFEPTgOsmw0pFF2QaVZOY6SGhAUM8TkIKHi4+DYTQRpCafvfg/h7l9uH2Ofexjc858fsl3bqu63tfv+v8vtjmc64/9zmpKiRJ+rnFnoAkaWkwECRJgIEgSWoGgiQJMBAkSW3lYk/gRL3vfe+rtWvXLvY0JGlZeeKJJ/6iqlaNem/ZBsLatWuZnJxc7GlI0rKS5M+O956XjCRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQs408qn4y1O/7gpMZ//9ZPnKKZSNLS4RmCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSMEYgJPlAkieHXj9K8rkkFyR5JMlzvTx/aMwtSaaSHExy7VD96iRP9Xt3JEnXz0ryYNf3J1n7jnQrSTqueQOhqg5W1VVVdRVwNfBj4KvADmBfVa0D9vU2SdYDE8AVwGbgziQr+nB3AduBdf3a3PVtwKtVdTlwO3DbKelOkjS2hV4y2gR8t6r+DNgC7Or6LuC6Xt8CPFBVb1bV88AUcE2SS4BzquqxqirgvlljZo61B9g0c/YgSTo9FhoIE8CXe/3iqjoM0MuLur4aeHFozKGure712fVjxlTVUeA14MIFzk2SdBLGDoQk7wY+BfzefLuOqNUc9bnGzJ7D9iSTSSanp6fnmYYkaSEWcobwceCbVfVyb7/cl4Ho5ZGuHwIuHRq3Bnip62tG1I8Zk2QlcC7wyuwJVNXdVbWhqjasWrVqAVOXJM1nIYHwaX56uQhgL7C117cCDw3VJ/rJocsY3Dx+vC8rvZ5kY98fuHHWmJljXQ882vcZJEmnyVi/QjPJe4B/BPzLofKtwO4k24AXgBsAqupAkt3AM8BR4OaqeqvH3ATcC5wNPNwvgHuA+5NMMTgzmDiJniRJJ2CsQKiqHzPrJm9V/YDBU0ej9t8J7BxRnwSuHFF/gw4USdLi8JPKkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgSMGQhJzkuyJ8l3kjyb5CNJLkjySJLnenn+0P63JJlKcjDJtUP1q5M81e/dkSRdPyvJg13fn2TtKe9UkjSncc8Q/ivwh1X1d4APAs8CO4B9VbUO2NfbJFkPTABXAJuBO5Os6OPcBWwH1vVrc9e3Aa9W1eXA7cBtJ9mXJGmB5g2EJOcAvwTcA1BVP6mqHwJbgF292y7gul7fAjxQVW9W1fPAFHBNkkuAc6rqsaoq4L5ZY2aOtQfYNHP2IEk6PcY5Q3g/MA38dpJvJflCkvcCF1fVYYBeXtT7rwZeHBp/qGure312/ZgxVXUUeA24cPZEkmxPMplkcnp6eswWJUnjGCcQVgIfBu6qqg8Bf0VfHjqOUd/Z1xz1ucYcW6i6u6o2VNWGVatWzT1rSdKCjBMIh4BDVbW/t/cwCIiX+zIQvTwytP+lQ+PXAC91fc2I+jFjkqwEzgVeWWgzkqQTN28gVNWfAy8m+UCXNgHPAHuBrV3bCjzU63uBiX5y6DIGN48f78tKryfZ2PcHbpw1ZuZY1wOP9n0GSdJpsnLM/f418KUk7wa+B/wzBmGyO8k24AXgBoCqOpBkN4PQOArcXFVv9XFuAu4FzgYe7hcMbljfn2SKwZnBxEn2JUlaoLECoaqeBDaMeGvTcfbfCewcUZ8ErhxRf4MOFEnS4vCTypIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJLWxAiHJ95M8leTJJJNduyDJI0me6+X5Q/vfkmQqycEk1w7Vr+7jTCW5I0m6flaSB7u+P8naU9ynJGkeCzlD+IdVdVVVzfxu5R3AvqpaB+zrbZKsByaAK4DNwJ1JVvSYu4DtwLp+be76NuDVqrocuB247cRbkiSdiJO5ZLQF2NXru4DrhuoPVNWbVfU8MAVck+QS4JyqeqyqCrhv1piZY+0BNs2cPUiSTo9xA6GAryd5Isn2rl1cVYcBenlR11cDLw6NPdS11b0+u37MmKo6CrwGXDh7Ekm2J5lMMjk9PT3m1CVJ41g55n4fraqXklwEPJLkO3PsO+o7+5qjPteYYwtVdwN3A2zYsOFt70uSTtxYZwhV9VIvjwBfBa4BXu7LQPTySO9+CLh0aPga4KWurxlRP2ZMkpXAucArC29HknSi5g2EJO9N8osz68CvAk8De4GtvdtW4KFe3wtM9JNDlzG4efx4X1Z6PcnGvj9w46wxM8e6Hni07zNIkk6TcS4ZXQx8te/xrgR+t6r+MMmfALuTbANeAG4AqKoDSXYDzwBHgZur6q0+1k3AvcDZwMP9ArgHuD/JFIMzg4lT0JskaQHmDYSq+h7wwRH1HwCbjjNmJ7BzRH0SuHJE/Q06UCRJi8NPKkuSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktTGDoQkK5J8K8nXevuCJI8kea6X5w/te0uSqSQHk1w7VL86yVP93h3pX9Sc5KwkD3Z9f5K1p7BHSdIYFnKG8Fng2aHtHcC+qloH7OttkqwHJoArgM3AnUlW9Ji7gO3Aun5t7vo24NWquhy4HbjthLqRJJ2wsQIhyRrgE8AXhspbgF29vgu4bqj+QFW9WVXPA1PANUkuAc6pqseqqoD7Zo2ZOdYeYNPM2YMk6fQY9wzht4BfB/5mqHZxVR0G6OVFXV8NvDi036Gure712fVjxlTVUeA14MJxm5Aknbx5AyHJJ4EjVfXEmMcc9Z19zVGfa8zsuWxPMplkcnp6eszpSJLGMc4ZwkeBTyX5PvAA8LEkvwO83JeB6OWR3v8QcOnQ+DXAS11fM6J+zJgkK4FzgVdmT6Sq7q6qDVW1YdWqVWM1KEkaz7yBUFW3VNWaqlrL4Gbxo1X1GWAvsLV32wo81Ot7gYl+cugyBjePH+/LSq8n2dj3B26cNWbmWNf313jbGYIk6Z2z8iTG3grsTrINeAG4AaCqDiTZDTwDHAVurqq3esxNwL3A2cDD/QK4B7g/yRSDM4OJk5iXJOkELCgQquobwDd6/QfApuPstxPYOaI+CVw5ov4GHSiSpMXhJ5UlSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCRgjEJL8fJLHk/xpkgNJfqPrFyR5JMlzvTx/aMwtSaaSHExy7VD96iRP9Xt3JEnXz0ryYNf3J1n7DvQqSZrDOGcIbwIfq6oPAlcBm5NsBHYA+6pqHbCvt0myHpgArgA2A3cmWdHHugvYDqzr1+aubwNerarLgduB206+NUnSQswbCDXwl735rn4VsAXY1fVdwHW9vgV4oKrerKrngSngmiSXAOdU1WNVVcB9s8bMHGsPsGnm7EGSdHqMdQ8hyYokTwJHgEeqaj9wcVUdBujlRb37auDFoeGHura612fXjxlTVUeB14ALR8xje5LJJJPT09NjNShJGs9YgVBVb1XVVcAaBt/tXznH7qO+s6856nONmT2Pu6tqQ1VtWLVq1TyzliQtxIKeMqqqHwLfYHDt/+W+DEQvj/Ruh4BLh4atAV7q+poR9WPGJFkJnAu8spC5SZJOzjhPGa1Kcl6vnw38CvAdYC+wtXfbCjzU63uBiX5y6DIGN48f78tKryfZ2PcHbpw1ZuZY1wOP9n0GSdJpsnKMfS4BdvWTQj8H7K6qryV5DNidZBvwAnADQFUdSLIbeAY4CtxcVW/1sW4C7gXOBh7uF8A9wP1JphicGUyciuYkSeObNxCq6tvAh0bUfwBsOs6YncDOEfVJ4G33H6rqDTpQJEmLw08qS5IAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1OYNhCSXJvmjJM8mOZDks12/IMkjSZ7r5flDY25JMpXkYJJrh+pXJ3mq37sjSbp+VpIHu74/ydp3oFdJ0hzGOUM4Cvy7qvq7wEbg5iTrgR3AvqpaB+zrbfq9CeAKYDNwZ5IVfay7gO3Aun5t7vo24NWquhy4HbjtFPQmSVqAeQOhqg5X1Td7/XXgWWA1sAXY1bvtAq7r9S3AA1X1ZlU9D0wB1yS5BDinqh6rqgLumzVm5lh7gE0zZw+SpNNjQfcQ+lLOh4D9wMVVdRgGoQFc1LutBl4cGnaoa6t7fXb9mDFVdRR4DbhwxNffnmQyyeT09PRCpi5JmsfYgZDkF4DfBz5XVT+aa9cRtZqjPteYYwtVd1fVhqrasGrVqvmmLElagLECIcm7GITBl6rqK11+uS8D0csjXT8EXDo0fA3wUtfXjKgfMybJSuBc4JWFNiNJOnHjPGUU4B7g2ar6zaG39gJbe30r8NBQfaKfHLqMwc3jx/uy0utJNvYxb5w1ZuZY1wOP9n0GSdJpsnKMfT4K/BPgqSRPdu0/ALcCu5NsA14AbgCoqgNJdgPPMHhC6eaqeqvH3QTcC5wNPNwvGATO/UmmGJwZTJxcW5KkhZo3EKrqfzP6Gj/ApuOM2QnsHFGfBK4cUX+DDhRJ0uLwk8qSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCS1eQMhyReTHEny9FDtgiSPJHmul+cPvXdLkqkkB5NcO1S/OslT/d4dSdL1s5I82PX9Sdae4h4lSWMY5wzhXmDzrNoOYF9VrQP29TZJ1gMTwBU95s4kK3rMXcB2YF2/Zo65DXi1qi4HbgduO9FmJEknbt5AqKo/Bl6ZVd4C7Or1XcB1Q/UHqurNqnoemAKuSXIJcE5VPVZVBdw3a8zMsfYAm2bOHiRJp8+J3kO4uKoOA/Tyoq6vBl4c2u9Q11b3+uz6MWOq6ijwGnDhqC+aZHuSySST09PTJzh1SdIop/qm8qjv7GuO+lxj3l6suruqNlTVhlWrVp3gFCVJo5xoILzcl4Ho5ZGuHwIuHdpvDfBS19eMqB8zJslK4FzefolKkvQOO9FA2Ats7fWtwEND9Yl+cugyBjePH+/LSq8n2dj3B26cNWbmWNcDj/Z9BknSabRyvh2SfBn4ZeB9SQ4B/xG4FdidZBvwAnADQFUdSLIbeAY4CtxcVW/1oW5i8MTS2cDD/QK4B7g/yRSDM4OJU9KZJGlB5g2Eqvr0cd7adJz9dwI7R9QngStH1N+gA0WStHj8pLIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJElt3l+hqbdbu+MPTnjs92/9xCmciSSdOkvmDCHJ5iQHk0wl2bHY85GkM82SCIQkK4D/DnwcWA98Osn6xZ2VJJ1ZlkQgANcAU1X1var6CfAAsGWR5yRJZ5Slcg9hNfDi0PYh4O/N3inJdmB7b/5lkoMn+PXeB/zFCY49KbntlB1q0Xo4hX4WeoCfjT7sYWk4HT387eO9sVQCISNq9bZC1d3A3Sf9xZLJqtpwssdZTPawdPws9GEPS8Ni97BULhkdAi4d2l4DvLRIc5GkM9JSCYQ/AdYluSzJu4EJYO8iz0mSzihL4pJRVR1N8q+A/wWsAL5YVQfewS950pedlgB7WDp+Fvqwh6VhUXtI1dsu1UuSzkBL5ZKRJGmRGQiSJOAMC4Tl8uMxklya5I+SPJvkQJLPdv2CJI8kea6X5w+NuaX7Opjk2sWb/bGSrEjyrSRf6+3l2MN5SfYk+U7/mXxkufWR5N/036Wnk3w5yc8v9R6SfDHJkSRPD9UWPOckVyd5qt+7I8mox9xPdx//uf8+fTvJV5OctyT6qKoz4sXgZvV3gfcD7wb+FFi/2PM6zlwvAT7c678I/F8GP9LjPwE7ur4DuK3X13c/ZwGXdZ8rFruPntu/BX4X+FpvL8cedgH/otffDZy3nPpg8MHP54Gze3s38E+Xeg/ALwEfBp4eqi14zsDjwEcYfN7pYeDjS6CPXwVW9vptS6WPM+kMYdn8eIyqOlxV3+z114FnGfyj3sLgf0708rpe3wI8UFVvVtXzwBSDfhdVkjXAJ4AvDJWXWw/nMPgHfQ9AVf2kqn7IMuuDwROFZydZCbyHwed8lnQPVfXHwCuzyguac5JLgHOq6rEa/F/1vqExp8WoPqrq61V1tDf/D4PPXsEi93EmBcKoH4+xepHmMrYka4EPAfuBi6vqMAxCA7iod1uqvf0W8OvA3wzVllsP7wemgd/uS19fSPJellEfVfX/gP8CvAAcBl6rqq+zjHoYstA5r+712fWl5J8z+I4fFrmPMykQxvrxGEtJkl8Afh/4XFX9aK5dR9QWtbcknwSOVNUT4w4ZUVsKfz4rGZzu31VVHwL+isGliuNZcn30dfYtDC5B/C3gvUk+M9eQEbWl8Gcxl+PNeUn3kuTzwFHgSzOlEbudtj7OpEBYVj8eI8m7GITBl6rqK11+uU8d6eWRri/F3j4KfCrJ9xlcnvtYkt9hefUAg3kdqqr9vb2HQUAspz5+BXi+qqar6q+BrwB/n+XVw4yFzvkQP70cM1xfdEm2Ap8E/nFfBoJF7uNMCoRl8+Mx+umBe4Bnq+o3h97aC2zt9a3AQ0P1iSRnJbkMWMfgBtSiqapbqmpNVa1l8N/60ar6DMuoB4Cq+nPgxSQf6NIm4BmWVx8vABuTvKf/bm1icF9qOfUwY0Fz7stKryfZ2L3fODRm0STZDPx74FNV9eOhtxa3j9N5t32xX8CvMXhi57vA5xd7PnPM8x8wOB38NvBkv34NuBDYBzzXywuGxny++zrIaX6KYox+fpmfPmW07HoArgIm+8/jfwLnL7c+gN8AvgM8DdzP4CmWJd0D8GUG9zz+msF3yNtOZM7Ahu77u8B/o39CwyL3McXgXsHMv+//sRT68EdXSJKAM+uSkSRpDgaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCS1/w9OSg60E8N+tQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 1238\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# compute and show histogram for sentence length\n",
    "plt.hist([len(sentence) for sentence in train_sentences], 20)\n",
    "plt.show()\n",
    "\n",
    "# compute max sentence length\n",
    "print('max length:', max([len(sentence) for sentence in train_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZL6OFL7_A6X2"
   },
   "outputs": [],
   "source": [
    "# train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ct5Cov4H6W_I"
   },
   "outputs": [],
   "source": [
    "# install transformers package\n",
    "!pip -q install transformers\n",
    "\n",
    "# import relevant classes for pretrained tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uNq82yj6Yi3",
    "outputId": "3fa4ab23-7657-4004-8269-28790e501c6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'tok',\n",
       " '##eni',\n",
       " '##zer',\n",
       " 'is',\n",
       " 'soo',\n",
       " '##oo',\n",
       " '##o',\n",
       " 'aw',\n",
       " '##eso',\n",
       " '##me',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tokenizer for a specific bert model (bert-base-cased)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# tokenize an example sentence\n",
    "tokenizer.tokenize('This tokenizer is sooooo awesome.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9gvZRHM6aXa",
    "outputId": "9ca3c878-512d-4dcb-8804-730b3cfd7291"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3708 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大福', '靠在', '父親', '的', '床', '邊', '打瞌睡']\n",
      "11 12\n",
      "['起步', '甚', '早', '的', '德國', '在', '這', '方面', '卻', '仍', '步履', '蹣跚']\n",
      "16 17\n",
      "['有', '了', '一對', '小', '犄角']\n",
      "6 7\n",
      "['枝頭', '上', '的', '小鳥', '總是', '吱吱喳喳', '的', '叫']\n",
      "11 14\n",
      "['電影', '中', '正面', '人物', '的', '行為', '必定', '不會', '和', '觀眾', '的', '認知', '產生', '牴觸']\n",
      "23 24\n",
      "['這句', '話', '就', '像', '是', '堅強', '的', '胳臂']\n",
      "10 11\n",
      "['日亞航', '目前', '所', '使用', '的', '機種', '主要', '為', '波音', '７４７', '及', 'ＤＣ－１０']\n",
      "21 24\n",
      "['外號', '泰山', '的', '黑索汀', '今天', '在', '英國', '保守黨', '黨魁', '選舉', '中', '來勢洶洶']\n",
      "24 25\n",
      "['你', '兒子', '賭氣', '不', '吃', '紅蘿蔔', '時', '可以', '連', '餓', '十九個', '不吭一氣']\n",
      "20 22\n",
      "['Segundo', 'o', 'dono', 'de', 'o', 'restaurante', ',', 'Fuad', 'Zegaid', ',', '61', ',', 'este', 'é', 'o', 'primeiro', 'caso', 'de', 'assalto', 'em', 'o', 'Dinho`s']\n",
      "27 28\n",
      "['再', '給', '人', '痛苦', '和', '懊悔']\n",
      "7 8\n",
      "['就', '在', '自己', '的', '小', '房間', '裡', '打瞌睡']\n",
      "11 12\n",
      "['他', '伸開', '胳臂']\n",
      "4 5\n",
      "['鼓聲', '咚咚']\n",
      "3 4\n",
      "['他', '伸開', '胳臂']\n",
      "4 5\n",
      "['鼓聲', '咚咚']\n",
      "3 4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def align_tokenizations(sentences, taggings):\n",
    "  bert_tokenized_sentences = []\n",
    "  aligned_taggings = []\n",
    "  count = 0\n",
    "  for sentence, tagging in zip(sentences, taggings):\n",
    "    # first generate BERT-tokenization\n",
    "    try:\n",
    "      bert_tokenized_sentence = tokenizer.tokenize(' '.join(sentence))\n",
    "    except:\n",
    "      print(\"Error\",sentence)\n",
    "    # print(bert_tokenized_sentence, sentence)\n",
    "    aligned_tagging = []\n",
    "    current_word = ''\n",
    "\n",
    "    index = 0 # index of current word in sentence and tagging\n",
    "    for token in bert_tokenized_sentence:\n",
    "      current_word += re.sub(r'^##', '', token) # recompose word with subtoken\n",
    "      # print(index, token, len(sentence)) #, sentence)\n",
    "      try: \n",
    "        sentence[index] = sentence[index].replace('\\xad', '') # fix bug in data\n",
    "      except:\n",
    "        print(sentence)\n",
    "        break  \n",
    "        # print(bert_tokenized_sentence)\n",
    "        \n",
    "\n",
    "      # note that some word factors correspond to unknown words in BERT\n",
    "      # print(token, sentence[index].startswith(current_word), sentence[index], current_word)\n",
    "      # assert token == '[UNK]' or sentence[index].startswith(current_word)\n",
    "\n",
    "      if token == '[UNK]' or sentence[index] == current_word: # if we completed a word\n",
    "        current_word = ''\n",
    "        aligned_tagging.append(tagging[index])\n",
    "        index += 1\n",
    "      else: # otherwise insert padding\n",
    "        aligned_tagging.append('<pad>')\n",
    "\n",
    "    # assert len(bert_tokenized_sentence) == len(aligned_tagging)\n",
    "\n",
    "    if(len(aligned_tagging)==len(bert_tokenized_sentence)):\n",
    "        \n",
    "      bert_tokenized_sentences.append(bert_tokenized_sentence)\n",
    "      aligned_taggings.append(aligned_tagging)\n",
    "    else: \n",
    "      print(len(aligned_tagging), len(bert_tokenized_sentence))\n",
    "      count+=1 \n",
    "\n",
    "  return bert_tokenized_sentences, aligned_taggings\n",
    "\n",
    "train_bert_tokenized_sentences, train_aligned_taggings = align_tokenizations(train_sentences, train_taggings)\n",
    "valid_bert_tokenized_sentences, valid_aligned_taggings = align_tokenizations(valid_sentences, valid_taggings)\n",
    "test_bert_tokenized_sentences, test_aligned_taggings = align_tokenizations(valid_sentences, valid_taggings)\n",
    "\n",
    "# print(train_bert_tokenized_sentences[42])\n",
    "# print(train_aligned_taggings[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYNv5Ln-6dG4",
    "outputId": "6d4b8563-12f1-426f-f97d-01c7fcf6658f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels: 15\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu') #\n",
    "\n",
    "import collections\n",
    "\n",
    "label_vocab = collections.defaultdict(lambda: len(label_vocab))\n",
    "label_vocab['<pad>'] = 0\n",
    "\n",
    "def convert_to_ids(sentences, taggings):\n",
    "  sentences_ids = []\n",
    "  taggings_ids = []\n",
    "  for sentence, tagging in zip(sentences, taggings):\n",
    "    sentence_tensor = torch.tensor(tokenizer.convert_tokens_to_ids(['[CLS]'] + sentence + ['SEP'])).long()\n",
    "    tagging_tensor = torch.tensor([0] + [label_vocab[tag] for tag in tagging] + [0]).long()\n",
    "\n",
    "    sentences_ids.append(sentence_tensor.to(device))\n",
    "    taggings_ids.append(tagging_tensor.to(device))\n",
    "  return sentences_ids, taggings_ids\n",
    "\n",
    "train_sentences_ids, train_taggings_ids = convert_to_ids(train_bert_tokenized_sentences, train_aligned_taggings)\n",
    "valid_sentences_ids, valid_taggings_ids = convert_to_ids(valid_bert_tokenized_sentences, valid_aligned_taggings)\n",
    "test_sentences_ids, test_taggings_ids = convert_to_ids(test_bert_tokenized_sentences, test_aligned_taggings)\n",
    "\n",
    "# print(train_sentences_ids[42])\n",
    "# print(train_taggings_ids[42])\n",
    "print('num labels:', len(label_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyWfx97VOhfs",
    "outputId": "e8a3c884-65e4-412d-e40a-779860528fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77199"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_taggings_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0dDD67Dx7lq",
    "outputId": "52593bff-2484-4031-acd0-1777844e4665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels: 15\n"
     ]
    }
   ],
   "source": [
    "print('num labels:', len(label_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JGAbUbD96fGf"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PosTaggingDataset(Dataset):\n",
    "  def __init__(self, sentences, taggings):\n",
    "    assert len(sentences) == len(taggings)\n",
    "    self.sentences = sentences\n",
    "    self.taggings = taggings\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    return self.sentences[i], self.taggings[i]\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEzvrYbK6g3s",
    "outputId": "c18c869e-4aaf-4789-f8f5-99eaefcd8294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(items):\n",
    "  max_len = max(len(item[0]) for item in items)\n",
    "\n",
    "  sentences = torch.zeros((len(items), max_len), device=items[0][0].device).long().to(device)\n",
    "  taggings = torch.zeros((len(items), max_len)).long().to(device)\n",
    "\n",
    "  for i, (sentence, tagging) in enumerate(items):\n",
    "    sentences[i][0:len(sentence)] = sentence\n",
    "    taggings[i][0:len(tagging)] = tagging\n",
    "\n",
    "  return sentences, taggings\n",
    "\n",
    "\n",
    "x, y = collate_fn([[torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])], [torch.tensor([1, 2]), torch.tensor([3, 4])]])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wIjkgyrJ7M8p"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(PosTaggingDataset(train_sentences_ids, train_taggings_ids), batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_loader = DataLoader(PosTaggingDataset(valid_sentences_ids, valid_taggings_ids), batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(PosTaggingDataset(test_sentences_ids, test_taggings_ids), batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZh3u_f67Otb",
    "outputId": "347dde24-5a6a-4ad2-bde5-7bde02be6833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "  def __init__(self, num_labels, embed_size=128, hidden_size=128):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(tokenizer.vocab_size, embed_size, padding_idx=tokenizer.pad_token_id)\n",
    "    self.rnn = nn.GRU(embed_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n",
    "    self.decision = nn.Linear(1 * 2 * hidden_size, num_labels) # size output by GRU is number of layers * number of directions * hidden size\n",
    "    self.to(device)\n",
    "  \n",
    "  def forward(self, sentences):\n",
    "    embed_rep = self.embedding(sentences)\n",
    "    word_rep, sentence_rep = self.rnn(embed_rep)\n",
    "    return self.decision(F.dropout(F.gelu(word_rep), 0.3))\n",
    "\n",
    "# check that model works on an arbitrary batch that contains two sentences of length 3\n",
    "rnn_model = RNNClassifier(len(label_vocab))\n",
    "with torch.no_grad():\n",
    "  y = rnn_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "\n",
    "# the expected shape is (batch size, max sentence length, number of labels)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMuj7hA97Slz",
    "outputId": "deb2e1e7-cdf3-4769-c9d3-6a96dba567cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.729502857327461, 0.10131068005940028)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perf(model, loader, alphabet=None):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  model.eval() # do not apply training-specific steps such as dropout\n",
    "  total_loss = correct = num_loss = num_perf = 0\n",
    "  for i, (x, y) in enumerate(loader):\n",
    "    with torch.no_grad(): # no need to store computation graph for gradients\n",
    "      # perform inference and compute loss\n",
    "      if(x.shape[1]>=512 or x.shape[0]!=64):\n",
    "        continue \n",
    "      if(alphabet):\n",
    "        y_scores = model(x, alphabet[i])\n",
    "      else:  \n",
    "        y_scores = model(x)\n",
    "      loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1)) # requires tensors of shape (num-instances, num-labels) and (num-instances)\n",
    "\n",
    "      # gather loss statistics\n",
    "      total_loss += loss.item()\n",
    "      num_loss += 1\n",
    "\n",
    "      # gather accuracy statistics\n",
    "      y_pred = torch.max(y_scores, 2)[1] # compute highest-scoring tag\n",
    "      mask = (y != 0) # ignore <pad> tags\n",
    "      correct += torch.sum((y_pred == y) * mask) # compute number of correct predictions\n",
    "      num_perf += torch.sum(mask).item()\n",
    "  return total_loss / num_loss, correct.item() / num_perf\n",
    "\n",
    "# without training, accuracy should be a bit less than 2% (chance of getting a label correct)\n",
    "perf(rnn_model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X4XqlwJR7UbW"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def fit(model, epochs, alphabet=None):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = num = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad() # start accumulating gradients\n",
    "      if(x.shape[1]>=512 or x.shape[0]!=64):\n",
    "        continue \n",
    "      else:  \n",
    "        if(alphabet):\n",
    "          y_scores = model(x, alphabet[i])\n",
    "        else:  \n",
    "          y_scores = model(x)\n",
    "        loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1))\n",
    "        loss.backward() # compute gradients though computation graph\n",
    "        optimizer.step() # modify model parameters\n",
    "        total_loss += loss.item()\n",
    "        num += 1\n",
    "    print(1 + epoch, total_loss / num, *perf(model, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEC39hKy8Mng"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "OfV0qauI7W80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.1061698165974635 0.06013810507953167 0.9145908851932815\n",
      "2 0.08364735104398394 0.3282135360315442 0.5633304740031545\n",
      "3 nan nan 0.0\n",
      "4 nan nan 0.0\n",
      "5 nan nan 0.0\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNClassifier(len(label_vocab))\n",
    "fit(rnn_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UP3Q77ll5nOC"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomedBiLstm(nn.Module):\n",
    "    def __init__(self,\n",
    "                 alphabet_size,\n",
    "                 vocab_size,\n",
    "                 word_embed_dim,\n",
    "                 char_embed_dim,\n",
    "                 char_hidden_dim,\n",
    "                 word_hidden_dim,\n",
    "                 n_tags,\n",
    "                 use_gpu):\n",
    "        super(CustomedBiLstm, self).__init__()\n",
    "        self.alphabet_size = alphabet_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word_embed_dim = word_embed_dim\n",
    "        self.char_embed_dim = char_embed_dim\n",
    "        self.char_hidden_dim = char_hidden_dim\n",
    "        self.word_hidden_dim = word_hidden_dim\n",
    "        self.n_tags = n_tags\n",
    "\n",
    "        self.char_embedding_layer = nn.Embedding(self.alphabet_size, self.char_embed_dim)\n",
    "        self.lower_LSTM = nn.LSTM(input_size=self.char_embed_dim,\n",
    "                                  hidden_size=self.char_hidden_dim,\n",
    "                                  batch_first=True)\n",
    "        \n",
    "        self.word_embedding_layer = nn.Embedding(self.vocab_size, self.word_embed_dim)\n",
    "        self.upper_LSTM = nn.LSTM(input_size=self.char_hidden_dim + self.word_embed_dim,\n",
    "                                  hidden_size=self.word_hidden_dim,\n",
    "                                  bidirectional=True)\n",
    "        self.hidden_to_tag = nn.Linear(self.word_hidden_dim*2, self.n_tags)\n",
    "\n",
    "    def forward(self, tokens_tensor, char_tensor):\n",
    "        char_embeds = self.char_embedding_layer(char_tensor)\n",
    "        lower_lstm_out, hidden = self.lower_LSTM(char_embeds)\n",
    "        last_state_lower_lstm = lower_lstm_out[-1]\n",
    "        tokens_embeds = self.word_embedding_layer(tokens_tensor)\n",
    "\n",
    "        final_embeds = torch.cat((last_state_lower_lstm, tokens_embeds), 1).view(tokens_tensor.shape[0], 1, -1)\n",
    "        upper_lstm_out, hidden = self.upper_LSTM(final_embeds)\n",
    "        out = self.hidden_to_tag(upper_lstm_out.view(tokens_tensor.shape[0], -1))\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZTcpdGF2VlNu"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext==0.6.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wQkvUyHUCpoF"
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "def build_alphabet_from_sentence_tokens(sentences_tokens):\n",
    "    \"\"\"\n",
    "    Build alphabet from tokens by converting tokens to character\n",
    "    :param sentences_tokens:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def to_char(tokens):\n",
    "      # try:\n",
    "      return [c for tok in tokens for c in list(tok)]\n",
    "      # except:\n",
    "      #   print(\"Error\")\n",
    "    sentences_char = [to_char(sent) for sent in sentences_tokens]\n",
    "    # print(sentences_char[0])\n",
    "\n",
    "    char_field = data.Field(tokenize=list, init_token='<root>')\n",
    "    fields = [('char', char_field)]\n",
    "    examples = [data.Example.fromlist([t], fields) for t in sentences_char]\n",
    "    # print(examples[0])\n",
    "    torch_dataset = data.Dataset(examples, fields)\n",
    "    char_field.build_vocab(torch_dataset)\n",
    "    return char_field.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cJmmVTZkNqPe"
   },
   "outputs": [],
   "source": [
    "alphabet = build_alphabet_from_sentence_tokens(train_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "BWGNj4fhr3Ne"
   },
   "outputs": [],
   "source": [
    "def build_vocab_from_sentences_tokens(sentences_tokens):\n",
    "    \"\"\"\n",
    "    use torch text to build vocab object from a list of sentences that is already tokenized in to tokens\n",
    "    :param sentences_tokens: list of list of tokens\n",
    "    :return: torchtext.vocab object\n",
    "    \"\"\"\n",
    "    token_field = data.Field(tokenize=list, init_token='<root>')\n",
    "    fields = [('tokens', token_field)]\n",
    "    examples = [data.Example.fromlist([t], fields) for t in sentences_tokens]\n",
    "    torch_dataset = data.Dataset(examples, fields)\n",
    "    token_field.build_vocab(torch_dataset)\n",
    "    return token_field.vocab\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_sentences_tokens(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLkFzFH-Kyy0",
    "outputId": "341aa8b1-410c-4b1d-c873-b24590c14c17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186648"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "mBfQp_fvMXFS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_one_batch(tokens, vocab, alphabet, tags, all_tags): #):\n",
    "    def token_to_char_tensor(tok):\n",
    "        tensor = torch.LongTensor([alphabet.stoi[c] for c in tok])\n",
    "        return tensor\n",
    "\n",
    "    tokens_tensor = torch.LongTensor([vocab.stoi[tok] for tok in tokens]).to(device)\n",
    "    # Perform padding for tokens\n",
    "    max_tok_len = max([len(tok) for tok in tokens])\n",
    "    # print(max_tok_len)\n",
    "    tokens_as_char = [token_to_char_tensor(tok) for tok in tokens]\n",
    "    for idx, tok in enumerate(tokens_as_char):\n",
    "        if len(tok) < max_tok_len:\n",
    "            paddings = torch.from_numpy(np.full(max_tok_len - len(tok), alphabet.stoi['<pad>']))\n",
    "            tok = torch.cat((tok, paddings))\n",
    "        tokens_as_char[idx] = tok\n",
    "    char_tensor = torch.stack([c_tnsr for c_tnsr in tokens_as_char], dim=1).to(device)\n",
    "    \n",
    "    tags_tensor = []\n",
    "    for tag in tags: \n",
    "        try: \n",
    "            tags_tensor.append(all_tags.index(tag))\n",
    "        except:\n",
    "            tags_tensor.append(0)\n",
    "            \n",
    "#     tags_tensor = torch.LongTensor([all_tags.index(tag) for tag in tags]).to(device)\n",
    "    tags_tensor = torch.LongTensor(tags_tensor).to(device)\n",
    "    return tokens_tensor, char_tensor, tags_tensor\n",
    "\n",
    "\n",
    "tokens_tensor, char_tensor, tags_tensor = get_one_batch(train_sentences[1], vocab,  alphabet, train_taggings[1], list(tagset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "xF6Wh9i15uNm"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "bilstm = CustomedBiLstm(alphabet_size = len(alphabet),\n",
    "                 vocab_size = len(vocab),\n",
    "                 word_embed_dim = 128,\n",
    "                 char_embed_dim = 100,\n",
    "                 char_hidden_dim = 100,\n",
    "                 word_hidden_dim = 100, n_tags=len(label_vocab), use_gpu=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "npMOf9Rq-sdL"
   },
   "outputs": [],
   "source": [
    "def perf_bilstm(model, loader):\n",
    "  criterion = nn.NLLLoss()\n",
    "  model.eval() # do not apply training-specific steps such as dropout\n",
    "  total_loss = correct = num_loss = num_perf = 0\n",
    "  # for i, (x, y) in enumerate(loader):\n",
    "  for i in range(len(valid_sentences)):\n",
    "    with torch.no_grad(): # no need to store computation graph for gradients\n",
    "      # perform inference and compute loss\n",
    "      # if(x.shape[1]>=512 or x.shape[0]!=64):\n",
    "      #   continue \n",
    "      # if(alphabet):\n",
    "      #   y_scores = model(x, alphabet[i])\n",
    "      # else:  \n",
    "      tokens_tensor, char_tensor, tag_tensor = get_one_batch(valid_sentences[i], vocab,  alphabet, valid_taggings[i], list(tagset))\n",
    "      y_scores = model(tokens_tensor, char_tensor)\n",
    "      loss = criterion(y_scores, tag_tensor)\n",
    "      # loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1)) # requires tensors of shape (num-instances, num-labels) and (num-instances)\n",
    "\n",
    "      # gather loss statistics\n",
    "      total_loss += loss.item()\n",
    "      num_loss += 1\n",
    "\n",
    "      # gather accuracy statistics\n",
    "      \n",
    "      y_pred = torch.max(y_scores, 1)[1]\n",
    "      mask = (tag_tensor != 0)\n",
    "      y_pred = y_pred[torch.where(tag_tensor!=0)]\n",
    "      tag_tensor = tag_tensor[torch.where(tag_tensor!=0)]\n",
    "\n",
    "    \n",
    "      correct += torch.sum((y_pred == tag_tensor)) #torch.sum((y_pred == tag_tensor)) # compute number of correct predictions\n",
    "      num_perf += len(y_pred)\n",
    "  return total_loss / num_loss, correct.item() / num_perf\n",
    "\n",
    "# without training, accuracy should be a bit less than 2% (chance of getting a label correct)\n",
    "# perf(rnn_model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "aWu7BTBn8PX3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.46909926785410677 0.37863804531904893 0.8839363329192672\n",
      "2 0.34231811047399835 0.36011845290907196 0.8956931240661464\n",
      "3 0.30537019414672795 0.3498213037611266 0.9030430082872023\n",
      "4 0.2819629779909792 0.36165203424894854 0.8945189567548636\n",
      "5 0.26502492568003233 0.3432860984393092 0.9045119772624768\n",
      "6 0.2605210868565978 0.3600860289489466 0.899649009642786\n",
      "7 0.26070244075720345 0.34731072475053165 0.9041466247729145\n",
      "8 0.24151677397327223 0.34749164177054204 0.9066637774423814\n",
      "9 0.23767418284759126 0.34991495553686525 0.9045069379177931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-797b0c84279b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mperf_bilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mfit_bilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-797b0c84279b>\u001b[0m in \u001b[0;36mfit_bilstm\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute gradients though computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# modify model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0mnum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mperf_bilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def fit_bilstm(model, epochs):\n",
    "  # criterion = nn.CrossEntropyLoss()\n",
    "  criterion = nn.NLLLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "#   model = model.to(device)\n",
    "#   train_sentences = train_sentences.to(device)\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = num = 0\n",
    "    # for i, (x, y) in enumerate(train_loader):\n",
    "    for i in range(len(train_sentences)):\n",
    "\n",
    "      tokens_tensor, char_tensor, tag_tensor = get_one_batch(train_sentences[i], vocab,  alphabet, train_taggings[i], list(tagset))\n",
    "\n",
    "      optimizer.zero_grad() # start accumulating gradients\n",
    "      # print(i, tokens_tensor.shape, char_tensor.shape)\n",
    "      # print(tokens_tensor)\n",
    "      y_scores = model(tokens_tensor, char_tensor)\n",
    "      \n",
    "      loss = criterion(y_scores, tag_tensor)\n",
    "      \n",
    "      # loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1))\n",
    "      loss.backward() # compute gradients though computation graph\n",
    "      optimizer.step() # modify model parameters\n",
    "      total_loss += loss.item()\n",
    "      num += 1\n",
    "    print(1 + epoch, total_loss / num, *perf_bilstm(model, valid_loader))\n",
    "\n",
    "fit_bilstm(bilstm, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "I1zhzatj7Yni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "class LinearProbeRandom(nn.Module):\n",
    "  def __init__(self, num_labels):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(tokenizer.vocab_size, 768)\n",
    "    self.probe = nn.Linear(768, num_labels)\n",
    "    self.to(device)\n",
    "\n",
    "  def parameters(self):\n",
    "    return self.probe.parameters()\n",
    "  \n",
    "  def forward(self, sentences):\n",
    "    with torch.no_grad(): # embeddings are not trained\n",
    "      word_rep = self.embedding(sentences)\n",
    "    return self.probe(word_rep)\n",
    "\n",
    "# the model should return a tensor of shape (batch size, sequence length, number of labels)\n",
    "random_model = LinearProbeRandom(len(label_vocab))\n",
    "with torch.no_grad():\n",
    "  y = random_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fw9eZ0Ha5tuN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "-0v6KL6M7axy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.4040638546306357 0.37073015777394175 0.46374646042594797\n",
      "2 0.37236741375957955 0.37348872505128383 0.4636486897811229\n",
      "3 0.371274112704349 0.3784518856368959 0.46136675982548864\n",
      "4 0.3744521512089917 0.3748056302405894 0.44985564994419697\n",
      "5 0.3740484201045609 0.37354439359158276 0.4566405637492275\n"
     ]
    }
   ],
   "source": [
    "random_model = LinearProbeRandom(len(label_vocab))\n",
    "fit(random_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "SClH8FAE7cK0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "class LinearProbeBert(nn.Module):\n",
    "  def __init__(self, num_labels):\n",
    "    super().__init__()\n",
    "    self.bert = AutoModel.from_pretrained('bert-base-multilingual-cased')\n",
    "    self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "    self.to(device)\n",
    "\n",
    "  def parameters(self):\n",
    "    return self.probe.parameters()\n",
    "  \n",
    "  def forward(self, sentences):\n",
    "    with torch.no_grad(): # no training of BERT parameters\n",
    "      word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "    return self.probe(word_rep)\n",
    "\n",
    "# the model should return a tensor of shape (batch size, sequence length, number of labels)\n",
    "bert_model = LinearProbeBert(len(label_vocab))\n",
    "y = bert_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02NsHaE_7d4K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.14632718710910786 0.10150510736741125 0.8663567521698626\n",
      "2 0.12898163423190723 0.10288331718649715 0.8662091738380512\n",
      "3 0.12970071518987888 0.10043854342307895 0.8644603706060857\n"
     ]
    }
   ],
   "source": [
    "bert_model = LinearProbeBert(len(label_vocab))\n",
    "fit(bert_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvd6mmNo7gwn"
   },
   "outputs": [],
   "source": [
    "print('RNN representation (supervised)', *perf(rnn_model, test_loader))\n",
    "print('RANDOM representation (unsupervised)', *perf(random_model, test_loader))\n",
    "print('BERT representation (unsupervised)', *perf(bert_model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJE3nLsr7ioB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uerakv1IEZO3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wW7sHBtEZO4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixMPqgvTEZO4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SgGCFdzEZO4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT-4-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
